# 2022.03.07-2022.03.13

## Algorithm
### 1. 题目
```
309. 最佳买卖股票时机含冷冻期
```
### 2. 题目描述
```
给定一个整数数组prices，其中第  prices[i] 表示第 i 天的股票价格 。​

设计一个算法计算出最大利润。在满足以下约束条件下，你可以尽可能地完成更多的交易（多次买卖一支股票）:

卖出股票后，你无法在第二天买入股票 (即冷冻期为 1 天)。
注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。

 

示例 1:

输入: prices = [1,2,3,0,2]
输出: 3 
解释: 对应的交易状态为: [买入, 卖出, 冷冻期, 买入, 卖出]
示例 2:

输入: prices = [1]
输出: 0
```

### 3. 解答：
```golang
func maxProfit(prices []int) int {
	n := len(prices)
	if n == 0 {
		return 0
	}
	// f[i][0]: maximum yield from holding stocks
	// f[i][1]: do not own stock, and in the frozen period of the cumulative maximum yield
	// f[i][2]: do not own stock, and not in the freeze period cumulative maximum yield
	f := make([][3]int, n)
	f[0][0] = -prices[0]
	for i := 1; i < n; i++ {
		f[i][0] = max(f[i-1][0], f[i-1][2]-prices[i])
		f[i][1] = f[i-1][0] + prices[i]
		f[i][2] = max(f[i-1][1], f[i-1][2])
	}
	return max(f[n-1][1], f[n-1][2])
}

func max(x, y int) int {
	if x > y {
		return x
	}
	return y
}
```
### 4. 说明
```
有三种状态：
我们目前持有一支股票，对应的「累计最大收益」记为 f[i][0]；
我们目前不持有任何股票，并且处于冷冻期中，对应的「累计最大收益」记为 f[i][1]；
我们目前不持有任何股票，并且不处于冷冻期中，对应的「累计最大收益」记为 f[i][2]。

状态转移方程：
如果当前持有股票，则有可能是之前持有的，这次没有买，也有可能是这次买的。如果是这次买的，则收益为f[i][2]-prices[i]。
f[i][0] = max(f[i-1][0], f[i-1][2]-prices[i])

如果当前不持有股票，且处于冷冻期，那么说明在头一天卖出了股票，那么收益应该是f[i-1][0]+prices[i]。
f[i][1] = f[i-1][0] + prices[i]

如果当前不持有股票，且不处于冷冻期，则可能头一天处于冷冻期或者不处于冷冻期。
f[i][2] = max(f[i-1][1], f[i-1][2])
```

## Review
### 1. 原文链接
[http://blog.cleancoder.com/uncle-bob/2014/11/19/GoingForTheGold.html](http://blog.cleancoder.com/uncle-bob/2014/11/19/GoingForTheGold.html)

### 2. 翻译
Thorns around the Gold

### 3. 点评
This article was inspired by The IsNullOrWhiteSpace trap by Mark Seemann (@ploeh). Mark’s article is well written and quite brief. Please read it before continuing.

The trap that Mark points out is a special case of a much more general trap that I call Grabbing for The Gold. I can demonstrate this trap by referring back to Mark’s article.

Notice that the first tests that Mark wrote were:
```
[InlineData("Seven Lions Polarized"  , "LIONS POLARIZED SEVEN"  )]
[InlineData("seven lions polarized"  , "LIONS POLARIZED SEVEN"  )]
[InlineData("Polarized seven lions"  , "LIONS POLARIZED SEVEN"  )]
[InlineData("Au5 Crystal Mathematics", "AU5 CRYSTAL MATHEMATICS")]
[InlineData("crystal mathematics au5", "AU5 CRYSTAL MATHEMATICS")]
```
He’s already fallen into the trap. Why? Because he grabbed for The Gold.

Gold and Thorns
The core functionality that Mark is trying to describe is one in which words are alphabetized. So, naturally, his tests reflect that core functionality. The core functionality is The Gold; and he grabbed for it.

The problem is that The Gold is protected by an invisible hedge of thorns that will entangle any unwitting programmer who, dazzled by The Gold, incautiously grabs for it. What is that hedge of thorns? In Mark’s case it is the null and blank input cases.

I have been following the TDD discipline for fifteen years now. In that time I’ve learned a lot about that invisible hedge of thorns. I’ve learned that it’s always there. I’ve learned that if you grab for The Gold too early, that invisible hedge will thwart your progress and tear your efforts to ribbons[1]. So the strategy I’ve learned to follow is to keep my eyes averted from “The Gold”, while probing for the hedge and clearing it away.

Probing and Clearing
Before I approach the core functionality, I write as many tests as I can that ignore the core functionality and deal instead with exceptional, degenerate, and ancillary behaviors; in that order. One by one, I write those tests, and then make them pass.

Exceptional Behaviors

These are behaviors that detect invalid inputs that the core functionality should never see. These behaviors return error codes, log error messages, and/or throw exceptions.

In Mark’s case handling the null input is the only exceptional behavior. But in more complex applications detecting exceptional cases can be a lot more challenging. Of course they include input validations. But they also include semantic violations such as deleting records that don’t exist; or adding records that already exist.

Degenerate Behaviors

These are inputs that cause the core functionality to do “nothing”. I put “nothing” in quotes because sometimes “nothing” can be relatively complicated.

In Mark’s case, the empty and blank strings are degenerate inputs. He eventually solved the problem of blanks and empties with a complex set of conditions and operations that returned an empty string if a sole blank or empty string was the input, and eliminated all blanks in every other case[2].

In general, degenerate conditions are things like blanks, empty strings, empty collections, zero length arrays, etc. In more complicated applications, a degenerate input can be quite complicated and require a great deal of processing. Consider, for example, a Java compiler processing a source file that contains thousands of lines containing nothing but semicolons and comments. What should it’s output be?

Ancillary Behaviors

These are sometimes the hardest to find. Ancillary behaviors are those that surround and support the core functionality; but are not part of it. For example, the getSize() function of a Stack. Reporting the size of a Stack is not related to its core LIFO functionality.

The thing about ancillary behaviors is that they frequently turn out to be useful to the core functionality in some in-obvious way. For example, it turns out that the size of a stack is the array index used for push and pop operations in fixed-length stacks. I often find that if all the ancillary behaviors are in place before I approach the core functionality, then the core functionality is much easier to implement.

These are the first tests I write, and make pass. I shy away from any tests that are close to the core functionality until I have completely surrounded the problem with passing tests that describe everything but the core functionality. Then, and only then, do I go get The Gold.

## Tip
### Makefile 隐含规则
* 使用隐含规则
```
foo : foo.o bar.o
    cc -o foo foo.o bar.o $(CFLAGS) $(LDFLAGS)
```
这个例子中，make调用的隐含规则是，把.o的目标的依赖文件置成.c，并使用C的编译命令cc -c $(CFLAGS) FOOT.C 来生成foo.o的目标 。

make和我们约定好了用C编译器cc生成.o文件的规则就是这个隐含规则。

```
foo.o : foo.p
```
依赖文件有可能变的没有意义。如果目录下存在了foo.c文件，那么我们的隐含规则一样会生效，并会通过foo.c第暗涌C的编译器生成foo.o文件。

如果你确实不希望任何隐含规则推导，那么，你就不要值写出“依赖规则”，而不写命令。

* 隐含规则一览
```
这里我们将讲述所有预先设置（也就是 make 内建）的隐含规则，如果我们不明确地写下规则，
那么，make 就会在这些规则中寻找所需要规则和命令。当然，我们也可以使用 make 的参数 -r 或
--no-builtin-rules 选项来取消所有的预设置的隐含规则。
当然，即使是我们指定了 -r 参数，某些隐含规则还是会生效，因为有许多的隐含规则都是使用了
“后缀规则”来定义的，所以，只要隐含规则中有“后缀列表”（也就一系统定义在目标 .SUFFIXES 的依
赖目标），那么隐含规则就会生效。默认的后缀列表是：.out, .a, .ln, .o, .c, .cc, .C, .p, .f, .F, .r, .y, .l, .s,
.S, .mod, .sym, .def, .h, .info, .dvi, .tex, .texinfo, .texi, .txinfo, .w, .ch .web, .sh, .elc, .el。具体的细节，
我们会在后面讲述。
还是先来看一看常用的隐含规则吧。
1. 编译 C 程序的隐含规则。
<n>.o 的目标的依赖目标会自动推导为 <n>.c ，并且其生成命令是 $(CC) –c $(CPPFLAGS)
$(CFLAGS)
2. 编译 C++ 程序的隐含规则。
<n>.o 的目标的依赖目标会自动推导为 <n>.cc 或是 <n>.C ，并且其生成命令是 $(CXX) –c
$(CPPFLAGS) $(CFLAGS) 。（建议使用 .cc 作为 C++ 源文件的后缀，而不是 .C ）
3. 编译 Pascal 程序的隐含规则。
<n>.o 的目标的依赖目标会自动推导为 <n>.p ，并且其生成命令是 $(PC) –c $(PFLAGS) 。
4. 编译 Fortran/Ratfor 程序的隐含规则。
<n>.o 的目标的依赖目标会自动推导为 <n>.r 或 <n>.F 或 <n>.f ，并且其生成命令是:
• .f $(FC) –c $(FFLAGS)
• .F $(FC) –c $(FFLAGS) $(CPPFLAGS)
• .f $(FC) –c $(FFLAGS) $(RFLAGS)
5. 预处理 Fortran/Ratfor 程序的隐含规则。
<n>.f 的目标的依赖目标会自动推导为 <n>.r 或 <n>.F 。这个规则只是转换 Ratfor 或有预处理的
Fortran 程序到一个标准的 Fortran 程序。其使用的命令是：
• .F $(FC) –F $(CPPFLAGS) $(FFLAGS)
• .r $(FC) –F $(FFLAGS) $(RFLAGS)
6. 编译 Modula-2 程序的隐含规则。
<n>.sym 的目标的依赖目标会自动推导为 <n>.def ，并且其生成命令是：$(M2C) $(M2FLAGS)
$(DEFFLAGS) 。<n>.o 的目标的依赖目标会自动推导为 <n>.mod ，并且其生成命令是：$(M2C)
$(M2FLAGS) $(MODFLAGS) 。
7. 汇编和汇编预处理的隐含规则。
<n>.o 的目标的依赖目标会自动推导为 <n>.s ，默认使用编译器 as ，并且其生成命令是：$ (AS)
$(ASFLAGS) 。<n>.s 的目标的依赖目标会自动推导为 <n>.S ，默认使用 C 预编译器 cpp ，并且
其生成命令是：$(AS) $(ASFLAGS) 。
8. 链接 Object 文件的隐含规则。
<n> 目标依赖于 <n>.o ，通过运行 C 的编译器来运行链接程序生成（一般是 ld ），其生成命令
是：$(CC) $(LDFLAGS) <n>.o $(LOADLIBES) $(LDLIBS) 。这个规则对于只有一个源文件的工程
有效，同时也对多个 Object 文件（由不同的源文件生成）的也有效。例如如下规则:
x : y.o z.o
并且 x.c 、y.c 和 z.c 都存在时，隐含规则将执行如下命令:
cc -c x.c -o x.o
cc -c y.c -o y.o
cc -c z.c -o z.o
cc x.o y.o z.o -o x
rm -f x.o
rm -f y.o
rm -f z.o
如果没有一个源文件（如上例中的 x.c）和你的目标名字（如上例中的 x）相关联，那么，你最好写
出自己的生成规则，不然，隐含规则会报错的。
9. Yacc C 程序时的隐含规则。
<n>.c 的依赖文件被自动推导为 n.y （Yacc 生成的文件），其生成命令是：$(YACC) $(YFALGS)
。（“Yacc”是一个语法分析器，关于其细节请查看相关资料）
10. Lex C 程序时的隐含规则。
<n>.c 的依赖文件被自动推导为 n.l（Lex 生成的文件），其生成命令是：$(LEX) $(LFALGS) 。（关
于“Lex”的细节请查看相关资料）
11. Lex Ratfor 程序时的隐含规则。
<n>.r 的依赖文件被自动推导为 n.l （Lex 生成的文件），其生成命令是：$(LEX) $(LFALGS) 。
12. 从 C 程序、Yacc 文件或 Lex 文件创建 Lint 库的隐含规则。
<n>.ln（lint 生成的文件）的依赖文件被自动推导为 n.c ，其生成命令是：$(LINT) $(LINTFALGS)
$(CPPFLAGS) -i 。对于 <n>.y 和 <n>.l 也是同样的规则。
```
* 隐含规则使用的变量
可以使用 make的-R或--no-builtin-variables参数来取消你所定义的变量对隐含规则的作用。
    - 关于命令的变量
```
• AR : 函数库打包程序。默认命令是 ar
• AS : 汇编语言编译程序。默认命令是 as
• CC : C 语言编译程序。默认命令是 cc
• CXX : C++ 语言编译程序。默认命令是 g++
• CO : 从 RCS 文件中扩展文件程序。默认命令是 co
• CPP : C 程序的预处理器（输出是标准输出设备）。默认命令是 $(CC) –E
• FC : Fortran 和 Ratfor 的编译器和预处理程序。默认命令是 f77
• GET : 从 SCCS 文件中扩展文件的程序。默认命令是 get
• LEX : Lex 方法分析器程序（针对于 C 或 Ratfor）。默认命令是 lex
• PC : Pascal 语言编译程序。默认命令是 pc
• YACC : Yacc 文法分析器（针对于 C 程序）。默认命令是 yacc
YACCR : Yacc 文法分析器（针对于 Ratfor 程序）。默认命令是 yacc –r
• MAKEINFO : 转换 Texinfo 源文件（.texi）到 Info 文件程序。默认命令是 makeinfo
• TEX : 从 TeX 源文件创建 TeX DVI 文件的程序。默认命令是 tex
• TEXI2DVI : 从 Texinfo 源文件创建军 TeX DVI 文件的程序。默认命令是 texi2dvi
• WEAVE : 转换 Web 到 TeX 的程序。默认命令是 weave
• CWEAVE : 转换 C Web 到 TeX 的程序。默认命令是 cweave
• TANGLE : 转换 Web 到 Pascal 语言的程序。默认命令是 tangle
• CTANGLE : 转换 C Web 到 C。默认命令是 ctangle
• RM : 删除文件命令。默认命令是 rm –f
```
    - 关于命令参数的变量
```
下面的这些变量都是相关上面的命令的参数。如果没有指明其默认值，那么其默认值都是空。
• ARFLAGS : 函数库打包程序 AR 命令的参数。默认值是 rv
• ASFLAGS : 汇编语言编译器参数。（当明显地调用 .s 或 .S 文件时）
• CFLAGS : C 语言编译器参数。
• CXXFLAGS : C++ 语言编译器参数。
• COFLAGS : RCS 命令参数。
• CPPFLAGS : C 预处理器参数。（C 和 Fortran 编译器也会用到）。
• FFLAGS : Fortran 语言编译器参数。
• GFLAGS : SCCS “get”程序参数。
• LDFLAGS : 链接器参数。（如：ld ）
• LFLAGS : Lex 文法分析器参数。
• PFLAGS : Pascal 语言编译器参数。
• RFLAGS : Ratfor 程序的 Fortran 编译器参数。
• YFLAGS : Yacc 文法分析器参数。
```

* 隐含规则链

有些时候，一个目标可能是被一系列的隐含规则所作用。例如，一个.o的文件生成，可能会先被Yacc的[.y]文件先生成.c，
然后再被C的编译器生成。我们把这一系列的隐含规则叫做“隐含规则链”。

在默认情况下，对于中间目标，它和一般的目标有两个地方有所不同：第一个不同是除非中间的目标不存在，才会引发中间规则。
第二个不同的是，只要目标成功产生，那么，产生最终目标过程中，所产生的中间目标会被以rm -f删除。

可以使用伪目标.INTERMEDIATE来强制声明一个文件或目标是中介目标。

可以使用伪目标.SECONDARY来阻止make自动删除中间目标。

在“隐含规则链”中，禁止同一个目标出现两次或两次以上，这样依赖，就可以防止在make自动推导时出现无限递归的情况。

Make会优化一些特殊的隐含规则，而不生成中间文件。如，从文件foo.c生成目标foo，按道理，make会编译生成中间文件foo.o，
然后连接成foo，但在实际情况下，这一动作可以被一条cc的命令完成（cc -o foo foo.c)，于是优化过的规则就不会生成中间文件。


## Share
### 如何通过区块链 + 隐私计算实现数据跨机构合规安全共享
[https://www.infoq.cn/article/vowCat1mQwWzyuYu2PcU](https://www.infoq.cn/article/vowCat1mQwWzyuYu2PcU)