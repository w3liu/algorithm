# 2020.01.20-2020.01.26

## Algorithm
### 1. 题目
```
求两数相加的和（001）
```
### 2. 题目描述
```
输入: (2 -> 4 -> 3) + (5 -> 6 -> 4)
输出: 7 -> 0 -> 8
说明: 342 + 465 = 807.
```

### 3. 解答：
```golang
type ListNode struct {
	Val  int
	Next *ListNode
}

func addTwoNumbers(l1 *ListNode, l2 *ListNode) *ListNode {
	var head *ListNode
	var previous *ListNode
	var current *ListNode
	var carry int
	for l1 != nil || l2 != nil {
		v1 := 0
		v2 := 0
		if l1 != nil {
			v1 = l1.Val
		}
		if l2 != nil {
			v2 = l2.Val
		}
		result := v1 + v2 + carry
		nodeVal := result % 10
		carry = result / 10
		current = &ListNode{
			Val: nodeVal,
		}
		if head == nil {
			head = current
		}
		if previous != nil {
			previous.Next = current
		}

		previous = current

		if l1 != nil {
			l1 = l1.Next
		}
		if l2 != nil {
			l2 = l2.Next
		}

	}

	if carry > 0 {
		current = &ListNode{
			Val: carry,
		}
		if head == nil {
			head = current
		}
		if previous != nil {
			previous.Next = current
		}
	}

	return head
}
```
### 4. 说明
这道题主要是需要用到10进制转化，通过取模、取余进行迭代操作。

## Review
### 1. 原文链接
[Partition Management in Hadoop](https://blog.cloudera.com/partition-management-in-hadoop/)

### 2. 翻译

Partition Management in Hadoop

Hadoop中的分区管理

In this post I’ll talk about the problem of Hive tables with a lot of small partitions and files and describe my solution in details.

在这篇帖子中我将谈论拥有许多小分区和文件的Hive表的问题以及我解决方案的详细描述。

A little background

一些背景

In my organization,  we keep a lot of our data in HDFS. 
Most of it is the raw data but a significant amount is the final product of many data enrichment processes. 
In order to manage all the data pipelines conveniently, 
the default partitioning method of all the Hive tables is hourly DateTime partitioning (for example: dt=’2019041316’).

在我们的单位，我们保留了许多数据在HDFS中。
其中大部分是原始数据，但是很大一部分是许多数据充实过程的最终产物。
为了方便管理所有的数据管道，
所有Hive表默认的分区方法是小时日期分区（例如: dt=’2019041316’）。

The many-small-files problem

许多小文件的问题

As I’ve written in a couple of my previous posts, one of the major problems of Hadoop is the “many-small-files” problem. 
When we have a data process that adds a new partition to a certain table every hour, and it’s been running for more than 2 years, we need to start handling this table. 
There are 24 * 365 * 2 (17,520) hours in 2 years time, so we’ll be having a table with almost 20k partitions. 
And I shall state that the volume we’re talking about here is around 1MB per hour. Now imagine having 500 tables of that sort.

正如我在之前的几篇文章所写的，Hadoop中的一个主要问题是“太多的小文件”问题。
当我们有一个每小时添加一个新的分区到一个确定的表中的处理进程，并且它已经运行了超过2年时间了的时候，我们就需要开始处理这个表了。
两年时间总共有24*365*2(17520)小时，因此我们将拥有一个接近2万个分区的表。
我要说的是，我们在这里讨论的体积大约是每小时1MB。现在想象一下有500张这样的表。

I don’t know if any of you tried to scan 20,000 partitions (i.e. files) just to read 20GB of data, but the overhead is enormous. 
No matter the technology: Spark, Hive, MapReduce, Impala, Presto— they all suffer extremely bad performance when there are too many small partitions. 
Now imagine having thousands of queries every day, scanning thousands of partitions per table.

我不知道你们当中是否有人尝试仅读取20G的数据而扫描2万个分区（即文件），但开销是巨大的。
无论哪种技术：Spark,Hive,MapReduce,Impala,Presto —— 当有太多的小分区的时候，他们都表现出极差的性能。
现在想象一下拥有每天有数千次的查询，扫描每张表的数千个分区。

The problem of HDFS, is that it’s simply a distributed filesystem — and nothing more. 
It’s not a storage layer that lets you ingest data and handles everything in the background. It’s a filesystem, plain and simple. 
That’s why I personally suggest you to store your final-product tables in a decent store like Apache Kudu, or an RDBMS like MySQL or PostgreSQL. 
But if for some reason you keep your data in the HDFS, you need to write your own storage management layer.

HDFS的这个问题，是因为它只是一个分布式文件系统——再也没有其他原因了。
它不是一个存储层让你接收数据并在后台处理所有数据。它是一个文件系统，清晰而简单。
这是为什么我个人建议你存储你的最终产品表在合适的存储系统中像Apache Kudu, 或者一个RDBMS类似于MySQL或PostgreSQL。
但是如果因为一些原因你保持你的数据在HDFS中，你需要编写你自己的存储管理层。



- 核心词汇
`raw` 原始的
`significant` 有重大意义的;显著的;有某种意义的;别有含义的;意味深长的
`enrichment` 丰富; 充实; 致富; 富裕
`plain` 清楚的


### 3. 点评
这是一篇关于Hadoop里的分区管理的文章，这篇只翻译了第一部分，主要说明了分布式存储系统分区太多的问题。

## Tip
### MongoDB开发最佳实践
1. 连接到MongoDB
    · 关于驱动程序：总是选择与所用之MongoDB相兼容的驱动程序。这可以很容易地从驱动兼容对照表中查到；
    
        · 如果使用第三方框架（如Spring Data）,则还需要考虑框架版本与驱动的兼容性；
        
    · 关于连接对象MongoClient：使用MongoClient对象连接到MongoDB实例时总是应该保证它单例，并且在这个生命周期
    中都从它获取其他操作对象。
    
    · 关于连接字符串：连接字符串中可以配置大部分连接选项，建议总是在连接字符串中配置这些选项；
    
    // 连接到复制集
    ```mongodb://节点1,节点2,节点3.../database?[options]```
    
    // 连接到分片集
    ```mongodb://mongos1,mongos2,mongos3.../database?[options]```
    
2. 常见连接字符串参数
    · maxPoolSize
        
        · 连接池大小
        
    · maxWaitTime
        
        · 建议设置，自动杀掉太慢的查询
        
    · writeConcern
        
        · 建议majority保证数据安全
        
    · readConcern
        
        · 对于数据一致性要求高的场景适当使用 
        
3. 连接字符串节点和地址
    · 无论对于复制集或分片集，连接字符串中都应尽可能多地提供节点地址，建议全部列出；
        
        · 复制集利用这些地址可以更有效地发现集群成员；
        
        · 分片集利用这些地址可以更有效的分散负载；
    
    · 连接字符串中尽可能使用与复制集内部配置相同的域名或IP；

4. 使用域名连接集群
    在配置集群时使用域名可以为集群变更时提供一层额外的保护。例如要将集群整体迁移到新网段，直接修改域名解析即可。
    
    另外，MongoDB提供的mongoDB+srv://协议可以提供额外一层保护。该协议允许通过域名解析得到所有mongos或节点的地址，
    而不是写在连接字符串中。
    
    mongodb+srv://server.example.com/
    
    Record TTL Class Priority Weight Port Target _mongodb._tcp.server.example.com.86400
    
    IN SRV 0 5 27317 mongodb1.example.com._mongodb._tcp.server.example.86400 IN SRV 0 5 27017 mongodb2.example.com.
    
5. 不要在mongos前面使用负载均衡
    基于前面提到的原因，驱动已经直销在不同的mongos之间实现负载均衡，而复制集则需要根据节点的角色来选择发送请求的目标。
    如果在mongos或复制集上层部署负载均衡：
    
    · 驱动会无法探测具体那个节点存活，从而无法完成自动故障恢复；
    
    · 驱动会无法判断游标是在哪个节点创建的，从而遍历游标时出错；
    
    结论：不要在mongos或复制集上层放置负载均衡器，让驱动处理负载均衡和自动故障恢复。
    
6. 游标使用
    如果一个游标已经遍历完，则自动关闭；如果没有遍历完，则需要手动调用close()方法，否则该游标将在服务器上存在
    10分钟（默认值）后超时释放，造成不必要的资源浪费。
    
    但是，如果不能遍历完一个游标，通常意味着查询条件太宽泛，更应该考虑的问题是如何将条件收紧。
    
7. 关于查询及索引
    · 每一个查询都必须要有对应的索引
    
    · 尽量使用覆盖索引Covered indexes（可以避免读数据文件）
    
    · 使用projection来减少返回客户端的文档内容
    
8. 关于写入
    · 在update语句里只包括需要更新的字段
    
    · 尽可能使用批量插入语句来提升写入性能
    
    · 使用TTL自动过期日志类型的数据
    
9. 关于文档结构
    · 防止使用太长的字段名（浪费空间）
    
    · 防止使用太深的数组嵌套（超过2层操作比较负责）
    
    · 不使用中文，标点符号等非拉丁字母作为字段名
    
10. 处理分页问题-避免使用count
    尽可能不要计算总页数，特别是数据量大和查询条件不能完整命中索引时。
    
    考虑以下场景：假设集合总共有1000W条数据，在没有索引的情况下考虑以下查询：
    
    ```
    db.coll.find({x:100}).limit(50);
    db.coll.count({x:100});
    ```
    
    · 前者只需要遍历前n条，直到找到50条队伍 x = 100 的文档即可结束；
    
    · 后者需要遍历完1000W条所有符合要求的文档才能得到结果。
    
    为了计算总页数而进行count()往往是拖慢页面真题加载速度的原因。
    
11. 处理分页问题——巧分页
    避免使用skip/limit形式的分页，特别是数据量大的时候；
   
    替代方案：使用条件查询+唯一条件排序；
    
    例如：
    
    第一页：db.find({}).sort({_id: 1}).limit(20);
    
    第二页：db.find({_id:{$gt:<第一页最后一个_id>}}).sort({_id: 1}).limit(20);
    
    第三页：db.find({_id:{$gt:<第二页最后一个_id>}}).sort({_id: 1}).limit(20);
    
    ······

12. 关于事务
    使用事务的原则：
    
    · 无论何时，事务的使用总是能避免则避免；
    
    · 模型设计先于事务，尽可能用模型设计规避事务；
    
    · 不要使用过大的事务（尽量控制在1000个文档更新以内）；
    
    · 当必须使用事务时，尽可能让涉及事务的文档分布在同一片上，这将有效地提高效率；
    

## Share
### MEGAEASE的远程工作文化
[MEGAEASE的远程工作文化](https://coolshell.cn/articles/20765.html)
```
这篇文章是耗子哥分享的远程办公方面的文章，写得非常不错，受益匪浅
```