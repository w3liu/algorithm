# 2020.01.06-2020.01.12

## Algorithm
### 1. 题目
```
814. 二叉树剪枝（025）
```
### 2. 题目描述
```
给定二叉树根结点 root ，此外树的每个结点的值要么是 0，要么是 1。

返回移除了所有不包含 1 的子树的原二叉树。

( 节点 X 的子树为 X 本身，以及所有 X 的后代。)
```
```
示例1:
输入: [1,null,0,0,1]
输出: [1,null,0,null,1]
 
解释: 
只有红色节点满足条件“所有不包含 1 的子树”。
右图为返回的答案。
```
![qr](./images/025_1.png)

```text
示例2:
输入: [1,0,1,0,0,0,1]
输出: [1,null,1,null,1]
```
![qr](./images/025_2.png)

```text
示例3:
输入: [1,1,0,1,1,0,1,0]
输出: [1,1,0,1,1,null,1]
```
![qr](./images/025_3.png)

### 3. 解答：
```golang
func pruneTree(root *TreeNode) *TreeNode {
	if root == nil {
		return root
	}
	if root.Left != nil {
		root.Left = pruneTree(root.Left)
	}
	if root.Right != nil {
		root.Right = pruneTree(root.Right)
	}
	if root.Val == 0 && root.Left == nil && root.Right == nil {
		return nil
	}
	return root
}
```
### 4. 说明
看到这道题第一时间就知道采用采用递归算法，递归最主要的是是找到中断条件，
这里的中断条件是当节点的值等于0且左右子节点都为空。

## Review
### 1. 原文链接
[MongoDB Sharding Best Practices](https://geekflare.com/mongodb-sharding-best-practices)

### 2. 翻译

MongoDB Sharding Best Practices 

MongoDB 分片最佳实践

While MongoDB “just works” out of the box for sharding, it doesn’t mean we can rest on our laurels. 
Sharding can make or break your project forever, depending on how well or poorly it was done.

MongoDB分片的开箱即用“只是能工作”，这并不意味着我们可以随意的使用它。
分片可以使得你的项目永久的成功或失败，取决于分片做的好坏。

Moreover, there are many small details to account for, failing which, it’s not uncommon to see projects collapse. 
The intent is not to scare you, but to highlight the need for planning and to be extremely careful even with small decisions.

此外，还有许多小细节需要说明，因为没有搞明白这些细节，导致项目崩溃的情况并不少见。
不是为了吓你，但要强调计划的必要性，即使小决定也要非常小心。

The Sharding Key inevitably controls sharding in MongoDB, so it’s ideal that we begin our survey with that.
在MongoDB中分片的键不可避免的控制着分片，因此我们最好从这个开始调查。

High cardinality

高基数

Cardinality means the amount of variation. 
For instance, a collection of a favorite country of 1 million people will have low variations (there are only so many countries in the world!), 
whereas a collection of their email addresses will have (perfectly) high cardinality.
Why does it matter? Suppose you pick a naive scheme that shards data based on a user’s first name.

基数是指变化量。
例如，一个拥有100万人口的最受欢迎的国家的集合会有很低的变化（这世界上只有这么多国家），
而他们的电子邮件地址集合将具有（完全）高基数。
为什么重要？假设你选择了一个天真的方案，该方案根据用户的名字分割数据。

[!qr](./images/025_r_1.png)

Here we have a rather simple arrangement; 
the incoming document is scanned for username, and depending on where the first letter lies in the English alphabet, it lands into one of the three shards. 
Similarly, searching for a document is easy: the details for “Peter”, for example, will be in the second shard for sure.

这里我们有个相当简单的安排；
扫描传入文档的用户名，根据第一个字母在英语字母表中的位置，将它存入三个分片中的一个。
类似地，搜索一个文档是简单点：例如，查询“Peter”的详细信息，肯定会在第二个分片中。

It all sounds good, but the point is, we don’t control the names of the incoming document users. 
What if we only get names in the B to F range most of the time?
If so, we’ll have what’s called a “jumbo” chunk in shard1: most of the system data will be crowded there, effectively turning the setup into a single database system.

这听起来不错，但是关键在于，我们不能控制传入文档的用户的名字。
如果我们得到的名字大部分时间只是在B到F的范围会怎么样？
如果这样，我们将有一个被称为“巨型”的块在shard1：大部分系统数据将被挤在那里，有效地将设置变成一个单一的数据库系统。

The Cure?

对策是什么？

Choose a key with high cardinality — for instance, the email address of the users, or you can even go for a compound shard key, which is a combination of multiple fields.

选择一个拥有高基数的键——例如，用户的邮箱地址，或者你甚至可以使用由多个字段联合的复合键。

Monotonically Changing

单调变化

A common mistake in MongoDB sharding is to use monotonically increasing (or auto-increasing, if you will) keys as the shard key.

在MongoDB分片过程中，一个常见的错误是使用单调递增（或者自动增长，如果你愿意）的键作为分片键。

Generally, the primary key of the document is used. 
The idea here is well-meaning, namely, as new documents keep being created, they will fall evenly into one of the shards available. 
Unfortunately, such a configuration is a classic mistake. 
This is so because if the shard key is always increasing, after a point data will start accumulating in the high-value side of the shards, causing an imbalance in the system.

通常，使用文档的主键。
这里的想法是善意的，也就是，随着新文档不断地被创建，它们将均匀地落入可以用的分片中。
不幸的是，这种配置是一个典型的错误。
这是因为如果片键总是增长，在一个点之后，数据将开始在分片的高值侧累积，导致系统不平衡。

[!qr](./images/025_r_2.png)

As you can see in the image, once we’re past the 20 range, all documents start getting collecting in Chunk C, causing a monolith there.
The solution is to go for hashed sharding key scheme, which creates a sharding key by hashing one of the provided fields and using that to determine the chunk.

正如你看到的图片，一旦我们超过20范围，所有的文档开始在Chunk C收集，在那里形成了一个整体。
解决方案是使用散列切分密钥方案，该方案通过散列提供的字段之一并使用该字段确定块来创建切分密钥。

[!qr](./images/025_r_3.png)

A hashed shard key looks like this:

一个散列片键看起来像这样：

```text
{
    "_id" :"6b85117af532da651cc912cd"
}
```

. . . and can be created in the Mongo client shell by using:

在Mongo客户端可以通过如下脚本创建：

```shell script
 db.collection.createIndex( { _id: hashedValue } )
```

Shard Early

尽早分片

One of the most useful advice direct from the trenches is to shard early, even if you end up with a small, two-chunk cluster. 
Once data has crossed 500 GB or something, sharding becomes a messy process in MongoDB, and you should be ready for nasty surprises. 
Besides, the rebalancing process consumes very high amounts of network bandwidth, which can choke the system if you’re not careful.

直接从实战中的到的直接建议是尽早分片，即使你最终得到一个小的，两块集群。
一旦数据跨过500GB或其他级别，在MongoDB中切分就变成了一个混乱的过程，你应该准备好迎接令人不快的惊喜。
此外，重新平衡过程会消耗非常高的网络带宽，如果不小心，可能会阻塞系统。

Not everyone is pro-sharding, though. As an interesting example (the learning is really in the comments), see this nice [Percona](https://www.percona.com/blog/2009/11/16/shard-early-shard-often/) blog.

不过，并不是所有人都支持分片。作为一个有趣的例子（学习真的在评论中），请看这个不错的[Percona](https://www.percona.com/blog/2009/11/16/shard-early-shard-often/)博客。

Running the balancer

运行平衡器

Another good idea is to monitor your traffic patterns and run the shard balancer only at low-traffic times. 
As I already mentioned, rebalancing itself takes considerable bandwidth, which could quickly bring the whole system to a crawl. 
Remember, imbalanced shards are not a cause for immediate panic.
Just let the normal usage persist, wait for low-traffic opportunities, and let the balancer do the rest!

另外一个方法是监控你的流量并在低流量时间段运行你的平衡器。
如前所述，重新平衡本身需要相当大的带宽，这可能会很快使整个系统陷入瘫痪。
记住，不平衡的碎片不是导致立即恐慌的原因。
只要让正常使用持续下去，等待低流量的机会，让平衡器做剩下的！

Here’s how you might accomplish this (assuming you have low traffic from 3 am to 5 am):

以下是您可能实现此目标的方法（假设您从凌晨3点到5点的流量较低）：

```shell script
use config 
db.settings.update( 
   { _id: "balancer" }, 
   { $set: { activeWindow : { start : "03:00", stop : "05:00" } } }, 
   { upsert: true } 
)
```

Conclusion

总结

Sharding and scaling any database is a tricky undertaking, but thankfully MongoDB makes it more manageable than other popular databases out there.

分割和扩展任何数据库都是一项棘手的工作，但幸好MongoDB使它比其他流行的数据库更易于管理。

There was indeed a time when MongoDB was not the right choice for any project (thanks to its several critical issues and default behaviors), but those are long gone. 
Along with sharding, rebalancing, auto-compression, aggregate-level distributed lock, and many such features, MongoDB has come miles ahead is today the software architect’s first choice.

确实曾经有一段时间，MongoDB不是任何项目的正确选择（由于它的几个关键问题和默认行为），但这些都已经过去了。
除了分片、重新平衡、自动压缩、聚合级分布式锁以及许多这样的特性，MongoDB已经领先了数英里，成为当今软件架构师的首选。

I hope this article was able to shed some light on what sharding is in MongoDB, and what the developer must take care of when going for scale. 

我希望这篇文章能够对MongoDB中的分片以及开发人员在进行扩容时必须注意的问题有所帮助。












- 核心词汇
`laurel` 月桂灌木、月桂树、荣誉、赞誉、荣耀
`collapse` 崩溃、倒闭
`uncommon` 不寻常
`account for` 说明、解释
`cardinality` 基数
`arrangement` 安排
`alphabet` 字母表
`jumbo` 巨型
`cure` 药、对策
`well-meaning` 善意的
`Unfortunately` 不幸的是

### 3. 点评

这篇文章介绍了MongoDB分片的最佳实践，其中最关键的是片键的选择，文中提到了“高基数”这个词，大概意思是片键能够匹配较多的文档，从而使得分片更加平衡。

## Tip
### 事务开发：写操作事务

- 什么是writeConcern？

writeConcern的属性包括：

1. w：决定一个写操作落到多少个节点上才算成功，w的取值包括：

. 0：发起写操作，不关心是否成功。

. 1~集群最大的节点数：写操作被复制到指定节点数才算成功。

. majority：写操作被复制到大多数节点才算成功。

发起写操作的程序将阻塞到写操作达到指定的节点数为止

2. j：表示是否先写日志，取值包括：

. true：写操作落到journal文件中才算成功。
. false：写操作到达内存即算成功。

3. wtimeout：表示写入超时时间，单位毫秒。

最佳实践：

```shell script
db.test.insert({title:"11111111", content:"2222222"}, {writeConcern:{w:"majority", j:true, wtimeout:3000}})  
```

- 注意事项

插入的时候有可能会报超时的错误，这个时候有可能已经写入成功，只是复制到其他复制集的时候超时了。



## Share
### 撮合引擎开发
[撮合引擎开发:MVP版本](https://keeganlee.me/post/matching/20191118/)